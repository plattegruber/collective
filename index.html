<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>AR Gallery</title>
  <link rel="stylesheet" href="/src/main.css">
  <style>
    :root{
      --ui-fg: #ffffff;
      --ui-fg-dim: #ffffffcc; /* 80% */
      --ui-shadow: 0 10px 40px rgba(0,0,0,.22);
      --bracket-thickness: 2.4; /* in SVG units */
    }
    html,body{height:100%;margin:0;background:#111;color:var(--ui-fg);font:16px/1.2 ui-sans-serif, system-ui, -apple-system, "Segoe UI", Roboto, "Helvetica Neue", Arial, "Apple Color Emoji","Segoe UI Emoji"}
    .app{position:relative;inline-size:100%;block-size:100%;overflow:hidden;touch-action:manipulation}

    /* Video and canvas for detector */
    #video-container {
      position: absolute;
      inset: 0;
      width: 100%;
      height: 100%;
    }

    video {
      position: absolute;
      inset: 0;
      inline-size: 100%;
      block-size: 100%;
      object-fit: cover;
      transform: translateZ(0);
      background: #000; /* fallback if no camera */
    }

    canvas {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      z-index: 1;
      pointer-events: none;
    }

    #loading { position:fixed; inset:0; display:grid; place-items:center; color:#fff; font-family: system-ui, sans-serif; z-index: 50; }

    /* Responsive overlay container */
    .overlay{
      position:absolute;inset:0;display:grid;place-items:center;padding:clamp(12px,4vmin,28px);
      pointer-events:none; /* let camera gestures pass through */
    }

    /* Soft vignette for legibility */
    .overlay::before{
      content:"";position:absolute;inset:0;
      background:radial-gradient(60% 60% at 50% 45%, rgba(0,0,0,.0) 0%, rgba(0,0,0,.35) 100%);
      pointer-events:none;
    }

    /* Stack: brackets + phrase */
    .hud{display:grid;gap:clamp(10px,2.6vmin,18px);justify-items:center;filter:drop-shadow(var(--ui-shadow))}

    /* SVG scales with viewport, maintains line proportions via vector-effect */
    .brackets{inline-size:min(70vmin, 560px);block-size:auto;opacity:.95}
    .brackets line, .brackets path{
      stroke:var(--ui-fg);fill:none;stroke-linecap:round;stroke-linejoin:round;
      stroke-width:var(--bracket-thickness);
      vector-effect:non-scaling-stroke;
    }
    /* Gentle pulse to feel alive (disabled for reduced motion) */
    @media (prefers-reduced-motion: no-preference){
      .pulse{animation:pulse 2.4s ease-in-out infinite}
      @keyframes pulse{0%,100%{opacity:.85}50%{opacity:1}}
    }

    /* Phrase styling */
    .phrase{
      pointer-events:auto; /* allow tap to cycle */
      text-align:center;letter-spacing:.01em;
      font-weight:600;
      font-size:clamp(18px, 3.6vmin, 28px);
      color:var(--ui-fg-dim);
      line-height:1.25;max-inline-size:min(80vw, 26ch)
    }

    /* Subtle sheen that sweeps across the text */
    .phrase.shimmer{
      background:linear-gradient(90deg, rgba(255,255,255,.5) 0%, rgba(255,255,255,1) 20%, rgba(255,255,255,.6) 40%, rgba(255,255,255,.85) 60%, rgba(255,255,255,.6) 80%, rgba(255,255,255,.5) 100%);
      -webkit-background-clip:text;background-clip:text;color:transparent;filter:drop-shadow(var(--ui-shadow));
      background-size:200% auto;
      animation:sheen 3.5s ease-in-out infinite;
    }
    @media (prefers-reduced-motion: reduce){ .phrase.shimmer{animation:none;background-size:auto;color:var(--ui-fg-dim)} }
    @keyframes sheen{ 0%{background-position:200% 0} 100%{background-position:-200% 0} }

    /* Hide helper */
    .is-hidden{opacity:0;visibility:hidden;transition:opacity .28s ease, visibility .28s step-end}
    .is-visible{opacity:1;visibility:visible;transition:opacity .28s ease}

    /* Custom transitions for artwork overlay */
    .artwork-overlay {
      position: fixed;
      top: 20px;
      bottom: 20px;
      left: 20px;
      right: 20px;
      background: rgba(0, 0, 0, 0.8);
      color: white;
      padding: 20px;
      border-radius: 12px;
      z-index: 10;
      pointer-events: none;
      opacity: 0;
      transform: translateY(20px);
      transition: opacity 0.3s ease, transform 0.3s ease;
    }

    .artwork-overlay.visible {
      opacity: 1;
      transform: translateY(0);
    }

    .artwork-overlay h2 {
      font-size: 1.5rem;
      font-weight: bold;
      margin-bottom: 8px;
    }

    .artwork-overlay p {
      margin: 4px 0;
      line-height: 1.6;
    }

    .artwork-overlay p:last-child {
      margin-top: 12px;
      font-size: 0.9rem;
      color: #ccc;
    }

    /* Error state */
    .error {
      color: #ff6b6b;
      text-align: center;
      padding: 20px;
    }
  </style>
</head>
<body>
  <div class="app" id="app">
    <div id="loading">Loading detector model...</div>

    <!-- Video and canvas for detector -->
    <div id="video-container">
      <video id="video" autoplay muted playsinline></video>
      <canvas id="canvas"></canvas>
    </div>

    <!-- Responsive overlay (SVG + text) -->
    <div class="overlay is-visible" id="overlay" aria-hidden="true">
      <div class="hud">
        <!-- Corner brackets (responsive SVG) -->
        <svg class="brackets pulse" viewBox="0 0 100 64" role="img" aria-label="framing guides">
          <!-- Top-left -->
          <path d="M8 18 L8 8 L28 8" />
          <!-- Top-right -->
          <path d="M92 18 L92 8 L72 8" />
          <!-- Bottom-left -->
          <path d="M8 46 L8 56 L28 56" />
          <!-- Bottom-right -->
          <path d="M92 46 L92 56 L72 56" />
        </svg>
        <div class="phrase shimmer" id="phrase" tabindex="0" aria-live="polite"></div>
      </div>
    </div>

    <!-- Static artwork information overlay -->
    <div id="artwork-info" class="artwork-overlay">
      <h2 id="artwork-title"></h2>
      <p id="artwork-artist"></p>
      <p id="artwork-materials"></p>
      <p id="artwork-description"></p>
    </div>
  </div>

  <script type="module">
    // Configuration
    const BASE_URL = import.meta.env.BASE_URL || '/';
    const CONFIDENCE_THRESHOLD = 0.70; // 70% confidence
    
    // Global state
    let artContent = {};
    let labels = {};
    let currentArtwork = null;
    let session = null;
    let isOnnxLoaded = false;

    // DOM elements
    const video = document.getElementById('video');
    const canvas = document.getElementById('canvas');
    const ctx = canvas.getContext('2d');
    const loading = document.getElementById('loading');
    const artworkOverlay = document.getElementById('artwork-info');
    const overlayEl = document.getElementById('overlay');
    const phraseEl = document.getElementById('phrase');

    // Phrase bank for dynamic overlay
    const phrases = [
      "point toward the art.",
      "frame the canvas.",
      "bring the wall into view.",
      "show the piece clearly.",
      "hold the painting in frame.",
      "focus on the artwork.",
      "line up with the picture.",
      "center the canvas here.",
      "aim at whatâ€™s on the wall.",
      "let the artwork fill the screen."
    ];

    function pickNewPhrase(){
      const current = phraseEl.textContent;
      const options = current ? phrases.filter(p => p !== current) : phrases;
      const next = options[Math.floor(Math.random()*options.length)];
      phraseEl.classList.remove('shimmer');
      // quick fade swap
      phraseEl.style.opacity = 0;
      window.setTimeout(()=>{
        phraseEl.textContent = next;
        phraseEl.style.opacity = 1;
        phraseEl.classList.add('shimmer');
      }, 140);
    }

    // Overlay show/hide API
    function hideOverlay(){ overlayEl.classList.remove('is-visible'); overlayEl.classList.add('is-hidden'); }
    function showOverlay(){ overlayEl.classList.remove('is-hidden'); overlayEl.classList.add('is-visible'); }

    // Initialize phrase and interaction
    function initOverlay() {
      pickNewPhrase();

      // Tap/click to cycle (esp. helpful on desktop while testing)
      phraseEl.addEventListener('click', pickNewPhrase);
      phraseEl.addEventListener('keydown', (e)=>{ if(e.key === 'Enter' || e.key === ' '){ pickNewPhrase(); }});

      // Optional: hide after tap on overlay area (mobile affordance)
      overlayEl.addEventListener('click', () => { hideOverlay(); });
    }
    
    // Load artwork content
    async function loadArtworkContent() {
      try {
        const response = await fetch(`${BASE_URL}data/art-content.v1.json`);
        artContent = await response.json();
        console.log('Loaded artwork content:', Object.keys(artContent).length, 'pieces');
      } catch (error) {
        console.error('Failed to load artwork content:', error);
      }
    }
    
    // Load model
    async function loadModel() {
      try {
        // Load manifest
        const manifestResponse = await fetch(`${BASE_URL}model-manifest.json`);
        const manifest = await manifestResponse.json();
        console.log('Model manifest:', manifest);
        
        // Load labels
        const labelsPath = manifest.labels ? `${BASE_URL}${manifest.labels}` : `${BASE_URL}models/detector/labels.json`;
        const labelsResponse = await fetch(labelsPath);
        labels = await labelsResponse.json();
        console.log('Loaded labels:', labels);
        
        // Load ONNX Runtime
        if (!isOnnxLoaded) {
          await new Promise((resolve, reject) => {
            const script = document.createElement('script');
            script.src = 'https://cdn.jsdelivr.net/npm/onnxruntime-web@1.20.0/dist/ort.min.js';
            script.onload = () => {
              isOnnxLoaded = true;
              resolve();
            };
            script.onerror = reject;
            document.head.appendChild(script);
          });
        }
        
        // Create ONNX session
        const modelPath = `${BASE_URL}${manifest.path || 'models/detector/model.onnx'}`;
        session = await window.ort.InferenceSession.create(modelPath, {
          executionProviders: ['wasm', 'webgl']
        });
        
        console.log('Model loaded successfully');
        loading.textContent = 'Starting camera...';
        
      } catch (error) {
        console.error('Failed to load model:', error);
        loading.innerHTML = '<div class="error">Failed to load detector model. Please refresh.</div>';
        throw error;
      }
    }
    
    // Process video frame
    async function processFrame() {
      if (!session || video.readyState < 2) return [];
      
      const vw = video.videoWidth;
      const vh = video.videoHeight;
      const sz = 320; // Model input size
      
      // Calculate scaling
      const scale = Math.min(sz/vh, sz/vw);
      const nw = (vw * scale) | 0;
      const nh = (vh * scale) | 0;
      const top = ((sz - nh) / 2) | 0;
      const left = ((sz - nw) / 2) | 0;
      
      // Draw to offscreen canvas
      const offCanvas = new OffscreenCanvas(sz, sz);
      const offCtx = offCanvas.getContext('2d');
      offCtx.fillStyle = 'black';
      offCtx.fillRect(0, 0, sz, sz);
      offCtx.drawImage(video, 0, 0, vw, vh, left, top, nw, nh);
      
      // Get image data and convert to NCHW
      const imageData = offCtx.getImageData(0, 0, sz, sz);
      const chw = new Float32Array(3 * sz * sz);
      for (let y = 0; y < sz; y++) {
        for (let x = 0; x < sz; x++) {
          const i = y * sz + x;
          const j = i * 4;
          chw[0 * sz * sz + i] = imageData.data[j] / 255;     // R
          chw[1 * sz * sz + i] = imageData.data[j + 1] / 255; // G
          chw[2 * sz * sz + i] = imageData.data[j + 2] / 255; // B
        }
      }
      
      // Run inference
      const input = new window.ort.Tensor('float32', chw, [1, 3, sz, sz]);
      const output = await session.run({ images: input });
      
      // Decode outputs
      const boxes = decodeOutputs(output, vw, vh, { left, top, scale });
      return boxes;
    }
    
    // Decode ONNX outputs
    function decodeOutputs(output, vw, vh, pad) {
      const names = Object.keys(output);
      let boxes = [];
      
      // Try to find boxes, scores, labels tensors
      if (names.includes('boxes') && names.includes('scores') && names.includes('labels')) {
        const bxT = output['boxes'];
        const scT = output['scores'];
        const lbT = output['labels'];
        const N = bxT.dims[1] || bxT.dims[0];
        
        for (let i = 0; i < N; i++) {
          const score = scT.data[i];
          const label = lbT.data[i];
          
          if (score >= CONFIDENCE_THRESHOLD && label > 0) {
            const offset = i * 4;
            let [x1, y1, x2, y2] = [
              bxT.data[offset],
              bxT.data[offset + 1],
              bxT.data[offset + 2],
              bxT.data[offset + 3]
            ];
            
            // Reverse letterbox padding
            x1 = (x1 - pad.left) / pad.scale;
            y1 = (y1 - pad.top) / pad.scale;
            x2 = (x2 - pad.left) / pad.scale;
            y2 = (y2 - pad.top) / pad.scale;
            
            // Clamp to video bounds
            x1 = Math.max(0, Math.min(vw, x1));
            y1 = Math.max(0, Math.min(vh, y1));
            x2 = Math.max(0, Math.min(vw, x2));
            y2 = Math.max(0, Math.min(vh, y2));
            
            if (x2 > x1 && y2 > y1) {
              boxes.push({ x1, y1, x2, y2, score, label });
            }
          }
        }
      }
      
      return boxes;
    }
    
    // Draw bounding boxes
    function drawBoxes(boxes) {
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      ctx.clearRect(0, 0, canvas.width, canvas.height);
      
      ctx.setLineDash([8, 6]);
      ctx.lineWidth = 3;
      ctx.strokeStyle = '#00e0ff';
      ctx.fillStyle = 'rgba(0, 0, 0, 0.6)';
      ctx.font = '16px system-ui';
      
      for (const box of boxes) {
        const x = box.x1;
        const y = box.y1;
        const w = box.x2 - box.x1;
        const h = box.y2 - box.y1;
        
        // Draw box
        ctx.strokeRect(x, y, w, h);
        
        // Draw label
        const labelText = labels[box.label] || `class_${box.label}`;
        const confidence = `${(box.score * 100).toFixed(0)}%`;
        const text = `${labelText} ${confidence}`;
        
        const metrics = ctx.measureText(text);
        ctx.fillRect(x, y - 25, metrics.width + 10, 22);
        ctx.fillStyle = '#fff';
        ctx.fillText(text, x + 5, y - 8);
        ctx.fillStyle = 'rgba(0, 0, 0, 0.6)';
      }
    }
    
    // Update artwork overlay
    function updateArtworkOverlay(boxes) {
      if (boxes.length === 0) {
        // No detection - hide artwork overlay and show instruction overlay
        if (currentArtwork) {
          artworkOverlay.classList.remove('visible');
          currentArtwork = null;
          showOverlay();
          // Cycle phrase when tracking is lost to keep it fresh
          pickNewPhrase();
        }
        return;
      }

      // Get the highest confidence detection
      const bestBox = boxes.reduce((best, box) =>
        box.score > best.score ? box : best
      );

      const labelText = labels[bestBox.label];
      if (!labelText) return;

      // Map label to artwork ID
      // Labels are like "2d:byrons_painting", we need to find matching artwork
      const artworkId = findArtworkByLabel(labelText);

      if (artworkId && artworkId !== currentArtwork) {
        const artwork = artContent[artworkId];
        if (artwork) {
          document.getElementById('artwork-title').textContent = artwork.title;
          document.getElementById('artwork-artist').textContent = `${artwork.artist}, ${artwork.year}`;
          document.getElementById('artwork-materials').textContent = artwork.materials;
          document.getElementById('artwork-description').textContent = artwork.description;

          artworkOverlay.classList.add('visible');
          currentArtwork = artworkId;
          // Hide instruction overlay when artwork is detected
          hideOverlay();
        }
      }
    }
    
    // Map label to artwork ID
    function findArtworkByLabel(label) {
      // Label from detector is already the artwork ID (e.g., "2d:byrons_painting")
      return artContent[label] ? label : null;
    }
    
    // Main detection loop
    
    async function detectLoop() {
      try {
        const boxes = await processFrame();
        drawBoxes(boxes);
        updateArtworkOverlay(boxes);
        
      } catch (error) {
        console.error('Detection error:', error);
      }
      
      requestAnimationFrame(detectLoop);
    }
    
    // Initialize app
    async function init() {
      try {
        // Load data in parallel
        await Promise.all([
          loadArtworkContent(),
          loadModel()
        ]);
        
        // Start camera
        const stream = await navigator.mediaDevices.getUserMedia({
          video: { facingMode: 'environment' }
        });
        video.srcObject = stream;
        
        // Wait for video to be ready
        await new Promise(resolve => {
          video.onloadedmetadata = resolve;
        });
        
        // Hide loading and initialize overlay
        loading.style.display = 'none';
        initOverlay();

        // Start detection loop
        detectLoop();
        
      } catch (error) {
        console.error('Initialization failed:', error);
        loading.innerHTML = '<div class="error">Failed to initialize. Please check camera permissions and refresh.</div>';
      }
    }
    
    // Start app
    init();
  </script>
</body>
</html>